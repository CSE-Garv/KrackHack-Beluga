import os
import hashlib
import yara
import pefile
import requests
import math
import json
import sys
import olefile
import pdfplumber

# OPTIONAL: VirusTotal API Key (Set to None to disable)
VIRUSTOTAL_API_KEY = "e887847c6c9a2a8daaeb67c8a4eacf75ecdc96991fdb1dc4dec8d5a8b0845428"


# Path to your YARA rule file
YARA_RULES_PATH = r"yara_rules.yar"

### Hash Calculation ###
def calculate_hashes(file_path):
    """Calculates MD5, SHA-1, and SHA-256 hashes of the file."""
    hashes = {"MD5": hashlib.md5(), "SHA1": hashlib.sha1(), "SHA256": hashlib.sha256()}
    with open(file_path, "rb") as f:
        while chunk := f.read(8192):
            for algo in hashes.values():
                algo.update(chunk)
    return {name: algo.hexdigest() for name, algo in hashes.items()}

### VirusTotal Lookup ###
def check_virustotal(file_hash):
    """Queries VirusTotal for hash reputation (if API key is set)."""
    if not VIRUSTOTAL_API_KEY:
        return None
    url = f"https://www.virustotal.com/api/v3/files/{file_hash}"
    headers = {"x-apikey": VIRUSTOTAL_API_KEY}
    try:
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            data = response.json()
            positives = data["data"]["attributes"]["last_analysis_stats"]["malicious"]
            return positives
        return None
    except:
        return None

### PE File Analysis ###
def detect_suspicious_strings(strings_list):
    """Scans extracted strings for suspicious content."""
    suspicious_keywords = {
        "rundll32.exe", "regsvr32.exe", "mshta.exe",
        "bypass", "unrestricted", "hidden", "-enc", "-encodedcommand",
        "Invoke-Expression", "IEX", "Start-Process", "ShellExecute",
        "VirtualAlloc", "VirtualProtect", "WriteProcessMemory",
        "CreateRemoteThread", "QueueUserAPC", "NtCreateThreadEx",
        "NtAllocateVirtualMemory", "NtWriteVirtualMemory",
        "NtQueueApcThread", "LoadLibraryA", "GetProcAddress",
        "ReflectiveLoader", "RunPE", "ManualMap",
        "HKEY_LOCAL_MACHINE", "HKEY_CURRENT_USER",
        "Software\\Microsoft\\Windows\\CurrentVersion\\Run",
        "Software\\Microsoft\\Windows\\CurrentVersion\\RunOnce",
        "Startup", "Autorun", "Scheduled Task",
        "http://", "https://", ".onion", "ftp://", "smb://",
        "WinSock", "WSAStartup", "socket", "connect", "bind",
        "send", "recv", "InternetOpen", "InternetConnect",
        "CreateProcessWithLogonW", "RemoteDesktop",
        "XOR", "RC4", "AESDecrypt", "CryptEncrypt",
        "CreateFileA", "WriteFile", "ReadFile",
        "MoveFileExA", "CopyFileA", "DeleteFileA",
        "IsDebuggerPresent", "CheckRemoteDebuggerPresent",
        "NtQueryInformationProcess",
        "RDTSCP", "cpuid", "VirtualBox", "VMware",
        "QEMU", "sandbox"
    }

    return [s for s in strings_list if s in suspicious_keywords]

def analyze_pe(file_path):
    """Extracts and analyzes PE header information."""
    try:
        pe = pefile.PE(file_path)
        imports = []
        entropy_scores = {}

        # Calculate entropy for each section
        for section in pe.sections:
            section_name = section.Name.decode().strip("\x00")
            entropy = calculate_entropy(section.get_data())
            entropy_scores[section_name] = round(entropy, 2)

        # Extract API imports
        if hasattr(pe, "DIRECTORY_ENTRY_IMPORT"):
            for entry in pe.DIRECTORY_ENTRY_IMPORT:
                for imp in entry.imports:
                    if imp.name:
                        imports.append(imp.name.decode())

        # Detect suspicious imports
        suspicious_imports = detect_suspicious_strings(imports)

        return {
            "suspicious_imports": suspicious_imports,
            "entropy": entropy_scores
        }
    
    except Exception as e:
        return {
            "suspicious_imports": [],
            "entropy": {},
            "error": str(e)
        }

def calculate_entropy(data):
    """Calculates Shannon entropy of a given byte sequence."""
    if not data:
        return 0.0
    byte_counts = {byte: data.count(byte) for byte in set(data)}
    total_bytes = len(data)
    return -sum((count / total_bytes) * math.log2(count / total_bytes) for count in byte_counts.values())

### PDF Analysis ###
def analyze_pdf(file_path):
    """Scans PDFs for suspicious content like JavaScript, embedded files, and metadata."""
    try:
        print("\nPDF Analysis:")
        with pdfplumber.open(file_path) as pdf:
            metadata = pdf.metadata
            metadata_info = {
                "Author": metadata.get('Author', 'Unknown'),
                "CreationDate": metadata.get('CreationDate', 'Unknown')
            }
        
        with open(file_path, "rb") as f:
            content = f.read().decode("latin-1", errors="ignore")

        suspicious_elements = ["/JavaScript", "/JS", "/OpenAction", "/Launch", "/SubmitForm"]
        found_elements = [elem for elem in suspicious_elements if elem in content]

        return {
            "metadata": metadata_info,
            "suspicious_elements": found_elements
        }
    except:
        return None

### DOCX Analysis ###
def analyze_docx(file_path):
    """Scans DOCX files for macros, OLE objects, and suspicious behavior."""
    try:
        docx_info = {"macros": False, "suspicious_keywords": []}

        if olefile.isOleFile(file_path):
            ole = olefile.OleFileIO(file_path)
            if ole.exists("Macros/VBA"):
                docx_info["macros"] = True
            ole.close()

        with open(file_path, "rb") as f:
            content = f.read().decode("latin-1", errors="ignore")

        suspicious_keywords = ["AutoOpen", "Shell", "WScript.Shell", "CreateObject"]
        found_keywords = [kw for kw in suspicious_keywords if kw in content]

        docx_info["suspicious_keywords"] = found_keywords
        return docx_info
    except:
        return None

### YARA Scan ###
def yara_scan(file_path):
    """Scans file with YARA rules."""
    try:
        if not os.path.exists(YARA_RULES_PATH):
            return []
        rules = yara.compile(filepath=YARA_RULES_PATH)
        matches = rules.match(file_path)
        return [match.rule for match in matches] if matches else []
    except:
        return []

### Main Execution ###
if __name__ == "__main__":
    if len(sys.argv) < 2:
        print(json.dumps({"error": "No file path provided"}))
        sys.exit(1)

    file_path = sys.argv[1]
    if not os.path.exists(file_path):
        print(json.dumps({"error": "File does not exist"}))
        sys.exit(1)

    file_extension = os.path.splitext(file_path)[-1].lower()

    # Calculate hashes
    hashes = calculate_hashes(file_path)

    # VirusTotal lookup
    vt_result = check_virustotal(hashes["SHA256"])

    # Perform analysis based on file type
    pe_info = None
    pdf_info = None
    docx_info = None

    risk_score = 0

    if file_extension in [".exe", ".dll"]:
        pe_info = analyze_pe(file_path)
        if pe_info and "entropy" in pe_info:
            risk_score += 0.5 if any(x > 7 for x in pe_info["entropy"].values()) else 0
        risk_score += len(pe_info["suspicious_imports"]) * 0.4
        yara_weight = 0.4

    elif file_extension == ".pdf":
        pdf_info = analyze_pdf(file_path)
        risk_score += len(pdf_info["suspicious_elements"]) * 2
        yara_weight = 2

    elif file_extension == ".docx":
        docx_info = analyze_docx(file_path)
        risk_score += 1 if docx_info["macros"] else 0
        risk_score += len(docx_info["suspicious_keywords"]) * 2
        yara_weight = 1.5

    # Run YARA scan
    yara_matches = yara_scan(file_path)

    # Determine risk score
    risk_score += len(yara_matches) * yara_weight
    if vt_result:
        risk_score += vt_result

    

    final_result = "Clean"
    if risk_score > 7:
        final_result = "Infected"
    elif risk_score > 4:
        final_result = "Suspicious"

    # Output JSON for Node.js
    result_data = {
        "hashes": hashes,
        "virustotal_hits": vt_result,
        "pe_info": pe_info if pe_info else None,
        "pdf_info": pdf_info if pdf_info else None,
        "docx_info": docx_info if docx_info else None,
        "yara_matches": yara_matches,
        "risk_score": f"{min(10, risk_score)}/10",
        "final_result": final_result
    }
    print(json.dumps(result_data))
